{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porting to Google Colab\n",
    "The following cell enables this notebook to run from Google Colab as well as from your local machine IDE.<br>\n",
    "You can change `root_directory` and/or `this_notebook_google_path` to point to the directory in your Google account, which contains this notebook, together with the `imgs` sub-directory and the rest of the files.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\projects\\RUNI\\Thesis\n",
      "Datasets path: d:\\projects\\RUNI\\Thesis\\datasets\n",
      "Output path: d:\\projects\\RUNI\\Thesis\\output\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "try:\n",
    "    from google.colab import drive as google_drive # type: ignore\n",
    "except:\n",
    "    # no Google Colab --> fall back to local machine\n",
    "    google_drive = None\n",
    "\n",
    "if google_drive is not None:\n",
    "    google_drive_directory = os.path.join('/','content','gdrive')\n",
    "    google_drive.mount(google_drive_directory)\n",
    "    all_projects_path = os.path.join(google_drive_directory, 'Othercomputers','My Laptop', 'projects')\n",
    "else:\n",
    "    all_projects_path = os.path.join('d:\\\\', 'projects')\n",
    "\n",
    "project_path = os.path.join(all_projects_path,'RUNI','Thesis')\n",
    "assert os.path.exists(project_path), f'Project path {project_path} not found!'\n",
    "# enable import python files from this notebook's path\n",
    "sys.path.append(project_path)\n",
    "# enable reading images and data files from this notebook's path\n",
    "os.chdir(project_path)\n",
    "\n",
    "datasets_path = os.path.join(project_path, 'datasets')\n",
    "assert os.path.exists(datasets_path), f'Datasets path {datasets_path} not found!'\n",
    "\n",
    "output_path = os.path.join(project_path, 'output')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "assert os.path.exists(output_path), f'Output path {output_path} not found!'\n",
    "\n",
    "print(f'Current working directory: {os.getcwd()}')\n",
    "print(f'Datasets path: {datasets_path}')\n",
    "print(f'Output path: {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba version: 0.60.0\n",
      "numba.njit is available.\n",
      "CUDA is available and will be used for GPU operations.\n",
      "Printing CUDA active device attributes:\n",
      "==================================================\n",
      "    Name:                               NVIDIA GeForce GTX 1650\n",
      "    Free Memory:                        3367680 [KB]\n",
      "    Total Memory:                       4193984 [KB]\n",
      "    Compute capability:                 7.5\n",
      "    Clock rate:                         1560.00 [MHz]\n",
      "    Memory clock rate:                  4001.00 [MHz]\n",
      "    Memory bus width:                   128 bits\n",
      "    Memory band width (theoretical)     128.03 [GByte/Sec]\n",
      "    Number of multiprocessors:          16\n",
      "    Minimal grid size:                  128\n",
      "    Maximum grid size:                  (2147483647, 65535, 65535)\n",
      "    Maximum block dimensions:           (1024, 1024, 64)\n",
      "    Maximum threads per block:          1024\n",
      "    Warp size:                          32\n",
      "    Maximum shared memory per block:    49152 [bytes]\n",
      "    Maximum registers per block:        65536\n",
      "    Total constant memory:              65536 [bytes]\n",
      "    Asynchronous engine count:          2\n",
      "    L2 cache size:                      1048576 [bytes]\n",
      "    ECC support enabled:                False\n"
     ]
    }
   ],
   "source": [
    "from python.hpc import HybridArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.metrics.metrics import test_speed_neto_detect_signal_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_monte = 10000\n",
    "N = 10000\n",
    "epsilon = 0.01\n",
    "n1 = int(epsilon*N)\n",
    "mu = 1.0\n",
    "num_execitions = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\venv\\thesis\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 10 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Test Speed Detect Signal AUC:   0%|          | 0/100 [00:00<?, ?step/s]d:\\venv\\thesis\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 10 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Test Speed Detect Signal AUC: 100%|██████████| 100/100 [00:00<00:00, 180.18step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done iter 1 out of 100\n",
      "Done iter 2 out of 100\n",
      "Done iter 3 out of 100\n",
      "Done iter 4 out of 100\n",
      "Done iter 5 out of 100\n",
      "Done iter 6 out of 100\n",
      "Done iter 7 out of 100\n",
      "Done iter 8 out of 100\n",
      "Done iter 9 out of 100\n",
      "Done iter 10 out of 100\n",
      "Done iter 11 out of 100\n",
      "Done iter 12 out of 100\n",
      "Done iter 13 out of 100\n",
      "Done iter 14 out of 100\n",
      "Done iter 15 out of 100\n",
      "Done iter 16 out of 100\n",
      "Done iter 17 out of 100\n",
      "Done iter 18 out of 100\n",
      "Done iter 19 out of 100\n",
      "Done iter 20 out of 100\n",
      "Done iter 21 out of 100\n",
      "Done iter 22 out of 100\n",
      "Done iter 23 out of 100\n",
      "Done iter 24 out of 100\n",
      "Done iter 25 out of 100\n",
      "Done iter 26 out of 100\n",
      "Done iter 27 out of 100\n",
      "Done iter 28 out of 100\n",
      "Done iter 29 out of 100\n",
      "Done iter 30 out of 100\n",
      "Done iter 31 out of 100\n",
      "Done iter 32 out of 100\n",
      "Done iter 33 out of 100\n",
      "Done iter 34 out of 100\n",
      "Done iter 35 out of 100\n",
      "Done iter 36 out of 100\n",
      "Done iter 37 out of 100\n",
      "Done iter 38 out of 100\n",
      "Done iter 39 out of 100\n",
      "Done iter 40 out of 100\n",
      "Done iter 41 out of 100\n",
      "Done iter 42 out of 100\n",
      "Done iter 43 out of 100\n",
      "Done iter 44 out of 100\n",
      "Done iter 45 out of 100\n",
      "Done iter 46 out of 100\n",
      "Done iter 47 out of 100\n",
      "Done iter 48 out of 100\n",
      "Done iter 49 out of 100\n",
      "Done iter 50 out of 100\n",
      "Done iter 51 out of 100\n",
      "Done iter 52 out of 100\n",
      "Done iter 53 out of 100\n",
      "Done iter 54 out of 100\n",
      "Done iter 55 out of 100\n",
      "Done iter 56 out of 100\n",
      "Done iter 57 out of 100\n",
      "Done iter 58 out of 100\n",
      "Done iter 59 out of 100\n",
      "Done iter 60 out of 100\n",
      "Done iter 61 out of 100\n",
      "Done iter 62 out of 100\n",
      "Done iter 63 out of 100\n",
      "Done iter 64 out of 100\n",
      "Done iter 65 out of 100\n",
      "Done iter 66 out of 100\n",
      "Done iter 67 out of 100\n",
      "Done iter 68 out of 100\n",
      "Done iter 69 out of 100\n",
      "Done iter 70 out of 100\n",
      "Done iter 71 out of 100\n",
      "Done iter 72 out of 100\n",
      "Done iter 73 out of 100\n",
      "Done iter 74 out of 100\n",
      "Done iter 75 out of 100\n",
      "Done iter 76 out of 100\n",
      "Done iter 77 out of 100\n",
      "Done iter 78 out of 100\n",
      "Done iter 79 out of 100\n",
      "Done iter 80 out of 100\n",
      "Done iter 81 out of 100\n",
      "Done iter 82 out of 100\n",
      "Done iter 83 out of 100\n",
      "Done iter 84 out of 100\n",
      "Done iter 85 out of 100\n",
      "Done iter 86 out of 100\n",
      "Done iter 87 out of 100\n",
      "Done iter 88 out of 100\n",
      "Done iter 89 out of 100\n",
      "Done iter 90 out of 100\n",
      "Done iter 91 out of 100\n",
      "Done iter 92 out of 100\n",
      "Done iter 93 out of 100\n",
      "Done iter 94 out of 100\n",
      "Done iter 95 out of 100\n",
      "Done iter 96 out of 100\n",
      "Done iter 97 out of 100\n",
      "Done iter 98 out of 100\n",
      "Done iter 99 out of 100\n",
      "Done iter 100 out of 100\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_speed_neto_detect_signal_auc(detect_signal=True, create_signal=False, N=N, num_monte=num_monte, num_executions=num_execitions, use_gpu=True, n1=n1, mu=mu)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
